{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"442ebfd9","cell_type":"markdown","source":"# computing $\\pi$ with GPU\n\nThe goal of this exercice is to compute an estimate of $\\pi$ on the GPU using [Monte Carlo integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration).\n\n\nThis technique consists in generating a number random 2D points with coordinates ranging from 0 to 1.\nand then the distance of these points to the origin.\n \nThe fraction of points falling whithin a distance 1.0 from the origin should approximate $\\pi/4$ with an increasing precision as the number of generated points increase.\n\n\n![](figures/MCpi.png)\n","metadata":{},"attachments":{}},{"id":"dd9e4a40","cell_type":"markdown","source":"### What CPU and GPU am I using?\n\nBefore we start, lets check what processor and GPU we will be using. Performance can vary a lot depending on which model we are using. Google Collab does not allow us to choose the model, but it is free.","metadata":{"id":"SICxTMkZg4Eh"}},{"id":"7e6deb94","cell_type":"code","source":"!echo \"CPU:\"\n!cat /proc/cpuinfo | grep name\n!echo \"GPU:\"\n!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47qfI-M8L46r","outputId":"e2eada9b-8d00-4d77-dadf-dfe92fff2b9f","trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:05:48.590087Z","iopub.execute_input":"2026-02-04T12:05:48.590451Z","iopub.status.idle":"2026-02-04T12:05:49.077246Z","shell.execute_reply.started":"2026-02-04T12:05:48.590415Z","shell.execute_reply":"2026-02-04T12:05:49.075998Z"}},"outputs":[{"name":"stdout","text":"CPU:\nmodel name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\nmodel name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\nmodel name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\nmodel name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\nGPU:\n/bin/bash: line 1: nvidia-smi: command not found\n","output_type":"stream"}],"execution_count":1},{"id":"869a6fb6","cell_type":"markdown","source":"## CPU implementation\n\nWe provide a standard Python implementation for reference.","metadata":{"id":"pSb5bpl6g-Iz"}},{"id":"7ad9b0ae","cell_type":"code","source":"from numpy.random import seed\nfrom numpy.random import random\nfrom numba import jit,njit,prange,cuda, types, float32\n\n@njit()\ndef estimate_pi_cpu( nb_points ):\n    nb_points_in = 0 # number of points in the circle\n    \n    for i in range(nb_points):\n        pt = random(2) # random 2D coordinates between 0 and 1\n        \n        dist = (pt**2).sum()**0.5  # distance from the origin\n        \n        nb_points_in += (dist <= 1.0) # increment if distance is <= 1\n\n    return (nb_points_in / nb_points)*4\n    \n\n# a single estimate of pi\nestimate_pi_cpu( 10**3 )    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:05:49.080384Z","iopub.execute_input":"2026-02-04T12:05:49.080833Z","iopub.status.idle":"2026-02-04T12:05:57.039791Z","shell.execute_reply.started":"2026-02-04T12:05:49.080794Z","shell.execute_reply":"2026-02-04T12:05:57.037864Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"3.172"},"metadata":{}}],"execution_count":2},{"id":"95d6143b","cell_type":"markdown","source":"The complexity is linear with the number of points generated. \nTherefore here we use a large vector size to increase the execution time. ","metadata":{"id":"hjyY1tO_h8hp"}},{"id":"3da572bf","cell_type":"code","source":"# timing the estimate with 2**24 points:\n%time pi_estimate = estimate_pi_cpu( 2**24 ) \nprint( pi_estimate )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:05:57.041569Z","iopub.execute_input":"2026-02-04T12:05:57.042758Z","iopub.status.idle":"2026-02-04T12:05:59.600966Z","shell.execute_reply.started":"2026-02-04T12:05:57.042691Z","shell.execute_reply":"2026-02-04T12:05:59.599743Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 2.48 s, sys: 15.6 ms, total: 2.49 s\nWall time: 2.55 s\n3.141481399536133\n","output_type":"stream"}],"execution_count":3},{"id":"f9e100a3","cell_type":"markdown","source":"## The CUDA implementation\n\nNow it's your turn to implement the CUDA kernel! \n\nThe main difficulties here reside in the implementation of the random number generation as well as the reduction to the final value. \n\nUse the numba documentation to help you:\n * [random number generation](https://nvidia.github.io/numba-cuda/user/random.html)\n * [reduction](https://nvidia.github.io/numba-cuda/user/intrinsics.html#example) (here we propose the use of an \"atomic\" operation rather than the actual numba.reduce)","metadata":{"id":"UwG7GcJuh1rc","tags":[]}},{"id":"2a21da4f","cell_type":"code","source":"@cuda.jit\ndef estimate_pi_gpu( ... ):\n    # generate a single point and check its distance\n    #  + handle the reduction\n\n# calling the function\nsize = 2**12\n\nblocksize = # block size = number of threads per block dimension\ngridsize = # grid size = number of blocks per grid dimension\n\n# Check!\nestimate_pi_gpu[gridsize, blocksize]()","metadata":{"id":"6XE-RxFQRQ29"},"outputs":[],"execution_count":null},{"id":"08c5d74a","cell_type":"markdown","source":"Now, time your function:","metadata":{}},{"id":"3028a628","cell_type":"code","source":"# calling the function\nsize = 2**24\n\nblocksize = # block size = number of threads per block dimension\ngridsize = # grid size = number of blocks per grid dimension\n\n\n%time pi_estimate = estimate_pi_gpu[gridsize, blocksize]()","metadata":{},"outputs":[],"execution_count":null},{"id":"66d2820a","cell_type":"markdown","source":"### additional tasks: Foolproof\n\nAdapt the previous code to handle sizes which are **not** a power of 2. **Hint:** you need to change both the kernel and the gridsize.\n","metadata":{"id":"ynqVJukXjQFQ","tags":[]}},{"id":"7f85e36d","cell_type":"code","source":"@cuda.jit\ndef estimate_pi_gpu( ... ):\n    # generate a single point and check its distance\n    #  + handle the reduction\n\n# calling the function\nsize = 2**12 + 1\n\nblocksize = # block size = number of threads per block dimension\ngridsize = # grid size = number of blocks per grid dimension\n\n# Check!\nestimate_pi_gpu[gridsize, blocksize]()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"l1qJI66nk-vv","outputId":"9269663e-d4a9-45e0-bf58-163bbc83f307"},"outputs":[],"execution_count":null}]}