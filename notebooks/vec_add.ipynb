{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SICxTMkZg4Eh"
   },
   "source": [
    "# What CPU and GPU am I using?\n",
    "\n",
    "Before we start, lets check what processor and GPU we will be using. Performance can vary a lot depending on which model we are using. Google Collab does not allow us to choose the model, but it is free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47qfI-M8L46r",
    "outputId": "e2eada9b-8d00-4d77-dadf-dfe92fff2b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "model name\t: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "GPU:\n",
      "Mon Feb  9 23:50:20 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 590.48.01              Driver Version: 590.48.01      CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0  On |                  Off |\n",
      "|  0%   44C    P8             29W /  450W |    3124MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3661      G   /usr/bin/gnome-shell                    203MiB |\n",
      "|    0   N/A  N/A            4275      G   /usr/bin/Xwayland                         8MiB |\n",
      "|    0   N/A  N/A            5141      G   /usr/lib/firefox/firefox                210MiB |\n",
      "|    0   N/A  N/A            6385      G   /usr/lib/slack/slack                     60MiB |\n",
      "|    0   N/A  N/A           32288    C+G   /usr/bin/ptyxis                          42MiB |\n",
      "|    0   N/A  N/A           38434      G   /opt/zoom/zoom                           87MiB |\n",
      "|    0   N/A  N/A           38697      G   /opt/zoom/ZoomClips                       6MiB |\n",
      "|    0   N/A  N/A           70256    C+G   /usr/bin/nautilus                        42MiB |\n",
      "|    0   N/A  N/A          121451      C   ...t/gpu_course/.venv/bin/python        580MiB |\n",
      "|    0   N/A  N/A          122304      C   ...t/gpu_course/.venv/bin/python        974MiB |\n",
      "|    0   N/A  N/A          131551      C   ...t/gpu_course/.venv/bin/python        646MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!echo \"CPU:\"\n",
    "!cat /proc/cpuinfo | grep name\n",
    "!echo \"GPU:\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSb5bpl6g-Iz"
   },
   "source": [
    "# Vector Addition Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j-2GrrEMNPLa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[5. 5. 5. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# The CUDA kernel\n",
    "# Goal: add 5 to a vector of zeros\n",
    "# in:  0 0 0 0 0 0...\n",
    "# out: 5 5 5 5 5 5...\n",
    "@cuda.jit\n",
    "def vec_add_constant(x, n, c):\n",
    "    # thread position in the grid\n",
    "    # shortcut for: i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    i = cuda.grid(1)\n",
    "\n",
    "    # Make sure we stop computing at n. \n",
    "    # If n is not a multiple of threads_per_blocks, \n",
    "    # it is likely that we have an extra block with empty values, some threads will have to wait\n",
    "    if i < n:\n",
    "        x[i] += c\n",
    "        \n",
    "n = 4096 # vector size\n",
    "c = 5.0 # constant to be added\n",
    "\n",
    "h_x = np.zeros(n, dtype=np.float32) # host array filled with zeros\n",
    "print(h_x)\n",
    "\n",
    "# copy h_x to a device array named d_x on the GPU\n",
    "d_x = cuda.to_device(h_x)\n",
    "\n",
    "threads_per_block = 32 # between 32 and 1024\n",
    "\n",
    "# compute the number of blocks necessary to solve the problem: 1024 / 256 = 4\n",
    "blocks = (n + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "# call the CUDA kernel on the GPU\n",
    "vec_add_constant[blocks, threads_per_block](d_x, n, c)\n",
    "\n",
    "# copy d_x back to h_x (from GPU to CPU)\n",
    "h_x = d_x.copy_to_host()\n",
    "\n",
    "print(h_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-acKLc1ksNt"
   },
   "source": [
    "## Exercise 1: Vector Addition\n",
    "\n",
    "Now it's your turn to implement the CUDA kernel! \n",
    "\n",
    "The goal is to add two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6XE-RxFQRQ29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[5. 5. 5. ... 5. 5. 5.]\n",
      "[5. 5. 5. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# CUDA kernel to add two vectors\n",
    "# in:\n",
    "# a:  0 0 0 0 0\n",
    "# b:  5 5 5 5 5\n",
    "# out:\n",
    "# c:  5 5 5 5 5\n",
    "@cuda.jit\n",
    "def vec_add(a, b, c, n):\n",
    "    i = cuda.grid(1)\n",
    "\n",
    "    # TODO: finish the kernel\n",
    "\n",
    "n = 4096 # vector size\n",
    "c = 5.0 # constant to be added\n",
    "\n",
    "h_a = np.zeros(n, dtype=np.float32) # host array filled with zeros\n",
    "h_b = np.full(n, 5.0, dtype=np.float32) # host array filled with 5s\n",
    "h_c = np.zeros(n, dtype=np.float32) # host array filled with zeros\n",
    "\n",
    "print(h_a)\n",
    "print(h_b)\n",
    "\n",
    "# copy h to d\n",
    "d_a = cuda.to_device(h_a)\n",
    "d_b = cuda.to_device(h_b)\n",
    "d_c = cuda.to_device(h_c)\n",
    "\n",
    "threads_per_block = 32 # between 32 and 1024\n",
    "\n",
    "# compute the number of blocks necessary to solve the problem: 1024 / 256 = 4\n",
    "blocks = (n + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "# call the CUDA kernel on the GPU\n",
    "vec_add[blocks, threads_per_block](d_a, d_b, d_c, n)\n",
    "\n",
    "# copy d to h\n",
    "h_a = d_a.copy_to_host()\n",
    "h_b = d_b.copy_to_host()\n",
    "h_c = d_c.copy_to_host()\n",
    "\n",
    "print(h_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibfklGMzlxgI",
    "tags": []
   },
   "source": [
    "## Exercise 2: Simple Memory Management\n",
    "\n",
    "By default, if we let Numba take care of the data transfers, Numba will copy all three arrays to and from the device everytime. \n",
    "\n",
    "This would be a good time to do some profiling using nvprof:\n",
    "```\n",
    "==8912== Profiling application: python vec_add.py\n",
    "==8912== Profiling result:\n",
    "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
    " GPU activities:   61.98%  79.743ms         6  13.290ms  5.6272ms  28.232ms  [CUDA memcpy DtoH]\n",
    "                   36.66%  47.159ms         6  7.8599ms  5.3962ms  12.592ms  [CUDA memcpy HtoD]\n",
    "                    1.36%  1.7535ms         2  876.77us  876.74us  876.80us  cudapy::__main__::dot_numba_cuda_kernel$241(Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
    "      API calls:   39.09%  83.395ms         6  13.899ms  5.7020ms  29.060ms  cuMemcpyDtoH\n",
    "                   38.00%  81.068ms         1  81.068ms  81.068ms  81.068ms  cuDevicePrimaryCtxRetain\n",
    "                   22.22%  47.419ms         6  7.9031ms  5.3943ms  12.724ms  cuMemcpyHtoD\n",
    "```\n",
    "\n",
    "**61.98**% of the total time is spent in the **[CUDA memcpy DtoH]** function, and **[CUDA memcpy HtoD]** function. **In total, 98.6% of the total execution time on the GPU is lost in data transfers...** Yes, only 1.36% of time is calculations.\n",
    "\n",
    "But in fact, we don't need to copy all three arrays everytime. We need to copy array a and b **to** the device (c will be set on the device), and we need to copy array c **from** the device to get the results.\n",
    "\n",
    "Below are some examples of how to control data transfers manually:\n",
    "\n",
    "```\n",
    "# Create device array d_a from array a and copy it to the device\n",
    "d_a = cuda.to_device(a)\n",
    "\n",
    "# Alternatively, create device array d_c from array c but DON'T copy it\n",
    "d_c = cuda.to_device(c, copy=False)\n",
    "\n",
    "# Copy the content of device array d_c to host array c\n",
    "d_c.copy_to_host(c)\n",
    "``` \n",
    "\n",
    "Then when calling the kernel function, use the freshly created device arrays rather than the host arrays:\n",
    "```\n",
    "vec_add[gridsize, blocksize](d_a, d_b, d_c)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB6P8qdittRC"
   },
   "source": [
    "\n",
    "If you did it right, it should be significantly faster!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vec_add_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (gpu-course)",
   "language": "python",
   "name": "gpu-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
